{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load and preprocess the Fashion MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], -1).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(X_test.shape[0], -1).astype('float32') / 255.0\n",
    "\n",
    "# Apply PCA to reduce dimensionality to 150\n",
    "pca = PCA(n_components=150)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_encoded = np.eye(10)[y_train]\n",
    "y_test_encoded = np.eye(10)[y_test]\n",
    "\n",
    "class SimpleNN:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.001):\n",
    "        # Initialize weights and biases\n",
    "        self.weights_input_hidden = np.random.randn(input_size, hidden_size) * np.sqrt(2. / input_size)\n",
    "        self.bias_hidden = np.zeros(hidden_size)\n",
    "        self.weights_hidden_output = np.random.randn(hidden_size, output_size) * np.sqrt(2. / hidden_size)\n",
    "        self.bias_output = np.zeros(output_size)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def relu_derivative(self, x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Forward pass\n",
    "        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
    "        self.hidden_output = self.relu(self.hidden_input)\n",
    "        self.final_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
    "        return self.softmax(self.final_input)\n",
    "\n",
    "    def backward(self, X, y, output):\n",
    "        # Calculate gradients\n",
    "        error = output - y\n",
    "        d_weights_hidden_output = np.dot(self.hidden_output.T, error)\n",
    "        d_bias_output = np.sum(error, axis=0)\n",
    "\n",
    "        hidden_error = np.dot(error, self.weights_hidden_output.T) * self.relu_derivative(self.hidden_input)\n",
    "        d_weights_input_hidden = np.dot(X.T, hidden_error)\n",
    "        d_bias_hidden = np.sum(hidden_error, axis=0)\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.weights_hidden_output -= self.learning_rate * d_weights_hidden_output\n",
    "        self.bias_output -= self.learning_rate * d_bias_output\n",
    "        self.weights_input_hidden -= self.learning_rate * d_weights_input_hidden\n",
    "        self.bias_hidden -= self.learning_rate * d_bias_hidden\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        # Cross-entropy loss\n",
    "        m = y_true.shape[0]\n",
    "        log_likelihood = -np.log(y_pred[range(m), y_true.argmax(axis=1)] + 1e-8)\n",
    "        return np.sum(log_likelihood) / m\n",
    "\n",
    "    def train(self, X, y, epochs, batch_size=64):\n",
    "        train_losses, train_accuracies = [], []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            indices = np.random.permutation(X.shape[0])\n",
    "            X, y = X[indices], y[indices]\n",
    "\n",
    "            for i in range(0, X.shape[0], batch_size):\n",
    "                batch_X = X[i:i + batch_size]\n",
    "                batch_y = y[i:i + batch_size]\n",
    "\n",
    "                output = self.forward(batch_X)\n",
    "                self.backward(batch_X, batch_y, output)\n",
    "\n",
    "            # Calculate loss and accuracy after each epoch\n",
    "            train_output = self.forward(X)\n",
    "            train_loss = self.compute_loss(y, train_output)\n",
    "            train_accuracy = np.mean(np.argmax(train_output, axis=1) == np.argmax(y, axis=1))\n",
    "            train_losses.append(train_loss)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            \n",
    "            print(f\"Epoch {epoch + 1}/{epochs} - Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "        # Plot the loss and accuracy\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(range(epochs), train_losses, label='Training Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(range(epochs), train_accuracies, label='Training Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        # Evaluation on the test set\n",
    "        test_output = self.forward(X)\n",
    "        test_loss = self.compute_loss(y, test_output)\n",
    "        test_accuracy = np.mean(np.argmax(test_output, axis=1) == np.argmax(y, axis=1))\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Create and train the neural network\n",
    "model = SimpleNN(input_size=150, hidden_size=256, output_size=10, learning_rate=0.001)\n",
    "model.train(X_train, y_train_encoded, epochs=25, batch_size=64)\n",
    "\n",
    "# Evaluate on test data\n",
    "model.evaluate(X_test, y_test_encoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
